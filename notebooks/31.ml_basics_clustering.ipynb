{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Клъстерен анализ\n",
    "\n",
    "Клъстерният анализ (КА) ни позволява да разделим извадка от наблюдения/обекти в непресичащи се, еднородни множества/групи, наречени клъстери. Всеки клъстер се състои от подобни обекти (спрямо някакви характеристики на обектите), а обекти в различните клъстери се различават съществено. От гледна точка на машинното самообучение, задачите за клъстезиция се отнася към групата на задачи за обучение без учител.\n",
    "\n",
    "Целта на клъстеризацията е търсене на скрита структура в данните. Задачата е сходна със задачата за класификация, като разликата се състои в това, че класовете данни не са предварително определени. Обикновено броят на клъстерите е неизвестен и се определя в хода на анализа.\n",
    "\n",
    "\n",
    "## Възможна ли е клъстеризацията?\n",
    "\n",
    "Теоремата за невъзможност на клъстеризация (An Impossibility Theorem for Clustering) на Джон Клейнбърг демонстрира, че клъстеризацията е невъзможна в най-строгата си форма. Трите аксиоми, които той представя:\n",
    "\n",
    "- **Независимост към скалата на данните (Scale-Invariance)** - ако трансформираме данните, така че всичко е отдалечено на равни разстояния в пространството, резултатът от КА не трябва да се промени.\n",
    "- **Консистентност (Consistency)** - ако разстоянията между клъстерите се увеличат, а тези в тях намалят, резултатът от КА не трябва да се промени.\n",
    "- **Богатство (Richness)** - функцията за клъстеризация трябва да може да създаде която и да е разбивка/клъстеризация на данните.\n",
    "\n",
    "не могат да бъдат удовлетворени задно, т.е. клъстеризацията е невъзможна. В практиката, последното изискване често е пренебрегвано и методите за КА широко използвани.\n",
    "\n",
    "## Методи за КА\n",
    "\n",
    "Нека $X = (x_1, \\ldots, x_n)$ е множество от обекти, а $D(x_i, x_j)$ е функция на разстоянието между обектите. Тогава, целта на КА е да намери брой на клъстерите $k$ и тяхното множество $Y = (y_1, \\ldots, y_k)$.\n",
    "\n",
    "Формирането на групи от КА трябва да бъдат еднородни отвътре и разнородни помежду си. Групирането се извършва на базата на някаква метрика за разстояние между обектите $D$.\n",
    "\n",
    "### Мерки за сходство и различие в КА\n",
    "\n",
    "Два обекта са идентични, ако разстоянието между тях е $0$. Колкото по-голямо е разстоянието между два обекта е, толкова по-голямо е различието между тях. Съществуват голям брой начини за оценка на разстояния между обектите в КА, някои от по-често употребяваните са:\n",
    "\n",
    "#### Евклидово разстояние\n",
    "\n",
    "Най-често използваната мярка за разстояние между интервални данни е евклидовот разстояние между два вектора \n",
    "$X_i = (x_{i1}, \\ldots, x_{ip})$ и $X_j = (x_{j1}, \\ldots, x_{jp})$:\n",
    "\n",
    "$$d(x_i, x_j) = \\sqrt{\\sum_{m = 1} ^ p (x_{im} - x_{jm})^2}, \\quad i,j = 1, \\ldots, n$$\n",
    "\n",
    "#### Квадрат на евклидовото разстояние\n",
    "\n",
    "$$d(x_i, x_j) = \\sum_{m = 1} ^ p (x_{im} - x_{jm})^2, \\quad i,j = 1, \\ldots, n$$\n",
    "\n",
    "#### Чебишево разстояние\n",
    "\n",
    "$$d(x_i, x_j) = \\max{|x_{im} - x_{jm}|}, \\quad i,j = 1, \\ldots, n$$\n",
    "\n",
    "#### Разстояние на Минковски от ред $r$\n",
    "\n",
    "$$d(x_i, x_j) = \\big(\\sum_{m = 1}^p\\big|x_{im} - x_{jm}\\big|^r\\big)^\\frac{1}{r}, \\quad i,j = 1, \\ldots, n$$\n",
    "\n",
    "където $n$ е броят на обектите.\n",
    "\n",
    "### Йерархичен КА\n",
    "\n",
    "Този метод последователно обединява малки клъстери в по-големи. В началото всеки обект се разглежда като клъстер, състоящ се от един елемент. На всяка стъпка процедурата намира двата най-близки клъстера и ги обединява в един. Алгоритъмът приключва, когато остане само едно множество.\n",
    "\n",
    "Резултатът от йерархичен КА е дендрограма - граф (дърво), в което всеки възел отразява една стъпка от процеса на обединяване, т.е. той носи допълнителна информация за величината на разстоянието между два клъстера в момента на обединение.\n",
    "\n",
    "Най-разпространените стратегии за обединяване на два клъстера $I$ и $J$ са:\n",
    "\n",
    "- **най-близък съсед** $d(I, J) = \\min\\limits_{i \\in I, j \\in J} d_{ij}$\n",
    "- **най-далечен съсед** $d(I, J) = \\max\\limits_{i \\in I, j \\in J} d_{ij}$\n",
    "- **средно разстояние** $d(I, J) = \\frac{1}{|I| + |J|}\\sum\\limits_{i \\in I, j \\in J} d_{ij}$\n",
    "- **средно претеглено разстояние** това разстояние зависи от х-ки на обектите, които се използват за КА и е специфично за всяка задача.\n",
    "\n",
    "#### Недостатъци на йерархичен КА\n",
    "\n",
    "- **скалируемост** - алгоритмите за йерархичен имат квадратична или кубична (по-често) сложност спрямо броя на входните данни\n",
    "- **не винаги намират глобален оптимум** - в естеството си, алгоритмите са лакоми, т.е. те търсят локален оптимум при всяко обединие на два клъстера.\n",
    "- **липса на еднозначност** - два различни алгоритъма може да получат различни резултати\n",
    "- **чувствителност към шум (крайности)**\n",
    "\n",
    "### Нейерархичен КА\n",
    "\n",
    "Нека имаме множество от обекти $1, \\ldots, n$ и се опитаме да ги разделим на фиксиран брой $k$ непресичащи се клъстери. Нейрархичните методи са основани на итеративни подходи за разделяне на съвкупност от данни. В процеса на делението се формират нови клъстери, докато се изпълни правило за спиране на деленето.\n",
    "\n",
    "#### Метод на пълните разстояния\n",
    "\n",
    "Нека си поставим задачата да минимизираме сумата от всички вътрешно клъстерни разстояния $A$ или да максимизираме сумата от всички между клъстерни разстояния $B$. Тогава $A + B = \\sum_{i < j}d_{ij}$.\n",
    "\n",
    "Нека имаме един обект $i \\in I(i)$ и проверим има ли смисъл той да бъде прехвърлен в клъстера $J \\neq I$. Трябва $d(i, I(i)) > d(i, J)$, т.е. при преминаване на $i$ в $J$ сумата $B$ ще нарастне с $d(i, I(i))$ и ще намалее с $d(i, J)$. Така получените необходими и достатъчни условия за оптимална клъстеризация на $k$ клъстера са:\n",
    "\n",
    "$$\\forall i: d(i, I(i)) \\leq \\min\\limits_{J \\neq I}d(i, J)$$\n",
    "\n",
    "#### Метод на средните разстояния\n",
    "\n",
    "Този метод е, може би, най-разпространеният метод за КА в практиката т.нар. $K$-means clustering. Той разглежда средните разстояния между обектите:\n",
    "\n",
    "$$d(i, J) = \\frac{1}{J}\\sum\\limits_{j \\in J}d(i, j) \\quad \\text{или} \\quad d(i, J) = ||x_i - \\overline{x}_j||$$\n",
    "\n",
    "#### Недостатъци на нейрархичните КА\n",
    "\n",
    "- **липса на йерархичност** - данни, които може да се разглеждат като йерархия не могат да бъдат добре представени\n",
    "- **количествени данни** - данните трябва да са количествени за да се приложат различните метрики за сходство\n",
    "\n",
    "#### Избор на броя на клъстерите\n",
    "\n",
    "Изборът на броя на клъстери $k$ често може да труден, тъй като не существуват еднозначни оценки за получените резултати от КА. Съществуват много практически подходи за справянето с този проблем, някои от тях са:\n",
    "\n",
    "- **метод на лакътя (elbow method)** - разглежда процента на обясненото отклонение като функция от броя на клъстерите. Трябва да изберем $k$, така че добавянето на още един клъстер не прави модела по-добър.\n",
    "\n",
    "- **метод на силуета (silhouette method)** - силуета на дадено обект е мярка за това колко близко той наподобява данните в клъстера си и колко слабо наподобява данните в другите клъстери. Оценка близка до $1$ показва, че обекта е в правилния клъстер, а тази близка до $-1$ ни показва, че се намира в грешен клъстер.\n",
    "\n",
    "### Плътностни методи\n",
    "\n",
    "Разгледаните методи могат да намират само сферични по форма клъстери и имат затруднения, когато клъстерите са с произволна форма. Такива клъстери могат да бъдат намерени с методи, които използват **плътност**. Основната идея е да се продължава разрастване на дадения клъстер до тогава, докато неговата плътност (брой обекти него) остава над определен праг. С други думи, за всеки обект, намиращ се в дадения клъстер, неговата околност със зададения радиус трябва да съдържа най-малко определен минимум от обекти. Тези методи се използват за филтриране на шума (крайности), както и за откриване на клъстери с произволна форма."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
