{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "plt.xkcd()\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covergence of Sequences of Random Variables\n",
    "\n",
    "## Analogy\n",
    "\n",
    "## Diagram\n",
    "\n",
    "## Example\n",
    "\n",
    "## Plain English\n",
    "\n",
    "## Technical Definition\n",
    "\n",
    "Let $Y_1, Y_2,\\ldots$ be a sequence of random variables (not necessarily independent), and let $a$ be a real number. We say that the sequence $Y_n$ converges to $a$ in probability, if for every $\\epsilon > 0$, we have:\n",
    "\n",
    "$$\\lim_{n \\to \\infty} P(\\lvert Y_n - a \\lvert \\geq \\epsilon) = 0.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Law of Large Numbers\n",
    "\n",
    "## Analogy\n",
    "\n",
    "## Diagram\n",
    "\n",
    "## Example\n",
    "\n",
    "## Plain English\n",
    "\n",
    "## Technical definition\n",
    "\n",
    "### Weak Law of Large Numbers\n",
    "\n",
    "This law asserts that the sample mean of a large number of independent identically distributed random variables is very close to the true mean, with high probability.\n",
    "\n",
    "Let $X_1, X_2, \\ldots$ be independently distributed random variables with mean $\\mu$. For every $\\epsilon > 0$, we have:\n",
    "\n",
    "$$P(\\lvert M_n - \\mu \\lvert \\geq \\epsilon) = P(\\lvert \\frac{X_1 + ... + X_n}{n} - \\mu \\lvert \\geq \\epsilon) \\to 0, \\text{as n} \\to \\infty$$\n",
    "\n",
    "The weak law of large numbers states that for large $n$, the bulk of the distribution of $M_n$ is concentrated near $\\mu$. That is, if we consider a positive length interval $[\\mu - \\epsilon, \\mu + \\epsilon]$ around $\\mu$, then there is high probability that $M_n$ will fall in that interval; as $n \\to \\infty$, this probability converges to 1. If $\\epsilon$ is very small, we may have to wait longer (i.e., need a larger value of n) before we can assert that $M_n$ is highly likely to fall in that interval.\n",
    "\n",
    "### Strong Law of Large Numbers\n",
    "\n",
    "This law is similar to its weak version in that it also deals with convergence of the sample mean to be true mean. It is dealing with a different type of convergence, though.\n",
    "\n",
    "Let $X_1, X_2, \\ldots$ be a sequence of independent identically distributed random variables with mean $\\mu$. Then, the sequence of sample means $M_n = \\frac{X_1 + ... + X_n}{n}$ converges to $\\mu$, with probability 1, in the sense that:\n",
    "\n",
    "$$P(\\lim_{n \\to \\infty} \\frac{X_1 + ... + X_n}{n} = \\mu) = 1.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central Limit Theorem\n",
    "\n",
    "## Analogy\n",
    "\n",
    "## Digram\n",
    "\n",
    "## Example\n",
    "\n",
    "## Plain English\n",
    "\n",
    "If we take sample size of n (e.g. 10 or 100), take the mean of it and plot the result, repeat that process m times (e.g. 1000 or 10,000), the distribution we're going to observe is going to be normal. As your sample sizes becomes larger (approaches infinity) we will observe smaller and smaller spread (deviation) from the mean.\n",
    "\n",
    "The theorem is surprisingly general - if you take the sample sum and plot those values, you will obtain a normal distribution, yet again!\n",
    "\n",
    "## Technical definition\n",
    "\n",
    "Let $X_1, X_2, \\ldots$ be a sequence of independent identically distributed random variables with common mean $\\mu$ and variance $\\sigma^2$, and define:\n",
    "\n",
    "$$Z_n = \\frac{X_1 + ... + X_n - n\\mu}{\\sigma\\sqrt{n}}$$\n",
    "\n",
    "Then, the CDF of $Z_n$ converges to the standard normal CDF\n",
    "\n",
    "$$\\phi(z) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^z e^{\\frac{-x^2}{2}}dx,$$\n",
    "\n",
    "in the sense that\n",
    "\n",
    "$$\\lim_{n \\to \\infty}P(Z_n \\leq z) = \\phi(z), \\text{for every } z.$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
