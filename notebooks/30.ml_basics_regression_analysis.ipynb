{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Регресионен анализ\n",
    "\n",
    "Регресионният анализ се използва за прогнозиране на количествени променливи. Той ни позволява да проверяваме хипотези за наличието на връзка и да я оценяме количествено.\n",
    "\n",
    "## Модел\n",
    "\n",
    "Регресия се нарича всяка комбинация между лин. независими базисни функции от обясняващи променливи (също наречени независими или предиктори) $X^(i)$ с неизвестни параметри $\\beta_i$. $X^{(i)}$ и $\\beta_i$ са фиксирани. Допълнително, имаме променлива $Y$ (наричаме обясняема, зависима или отклик), която е обект на нашият анализ. Тя е сл.в.\n",
    "\n",
    "Търсим отговори на следните въпроси:\n",
    "\n",
    "- Стойностите на отклика влияят ли се от предикторите?\n",
    "- Може ли да се избере модел на зависимостта и да се оценят параметрите му?\n",
    "- Адекватен ли е моделът, т.е. получената връзка отговоря ли на действителността?\n",
    "- Какви ст-сти може да очакваме за отклика при други ст-ти на предикторите (прогнозиране)?\n",
    "\n",
    "### Еднофакторни и многофакторни модели\n",
    "\n",
    "Според броя на обясняващите променливи, които играят ролята на фактори, регресионните модели се разделят на еднофакторни и многофакторни. В еднофакторните модели се изследва връзката между две явления $Y$ и $X$. Многофакторните модели изследват връзката между едно и други две или повече явления, които наричаме фактори.\n",
    "\n",
    "Общият вид на тези модели се дава от фомулите:\n",
    "\n",
    "- **Еднофакторен** $Y_i = f(X_i, \\epsilon_i)$\n",
    "- **Многофакторен** $Y_i = f(X_i^{(1)}, \\ldots, X_i^{(k)}, \\epsilon_i)$\n",
    "\n",
    "След построяване на модела може да правим предвиждане на ст-сти на бъдещи експерименти, като оценим $Y$. Тази оценка ще означим с $\\hat{Y}$ и ще пресмятаме като $\\hat{Y} = \\hat{f}(X)$.\n",
    "\n",
    "Разликите между реално наблюдаваните ст-сти $Y$ и ст-стите дадени от модела $\\hat{Y}$ се наричат **остатъци** (residuals). Те са сл. разпределени и независими помежду си. Колкото по-малки са техните ст-сти, толкова по-добре модела описва набл. ст-сти.\n",
    "\n",
    "### Проста линейна регресия\n",
    "\n",
    "Простата линейна регресия е еднофакторен модел и се представя с формулата:\n",
    "\n",
    "$$Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i$$\n",
    "\n",
    "където:\n",
    "\n",
    "- $\\beta_i$ са коефициентите на модела\n",
    "- $\\epsilon_i$ е грешката. Тя е сл. компонент с нормално разпределение и $E\\epsilon_i = 0$, т.е. $\\epsilon_i \\in N(0, \\sigma^2)$ т.е. предполагаме, че грешките от наблюденията са независими, еднакво разпределени гаусови сл.в. с нулево очакване.\n",
    "\n",
    "Прогнозата може да представим като:\n",
    "\n",
    "$$\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X$$\n",
    "\n",
    "където $\\hat{\\beta_0}, \\hat{\\beta_1}$ са оценки на коеф. на модела.\n",
    "\n",
    "Параметрите за модела са коефициентите $\\beta_0, \\beta_1$ и дисперсията на грешката $\\sigma^2$.\n",
    "\n",
    "### Х-ки на регресионните модели\n",
    "\n",
    "#### Извадков корелационен коефициент\n",
    "\n",
    "Нека имаме следните означения:\n",
    "\n",
    "$$\\text{SS}_x = \\sum \\big(X_i - \\overline{X}\\big)^2$$\n",
    "$$\\text{SS}_y = \\sum \\big(Y_i - \\overline{Y}\\big)^2$$\n",
    "$$\\text{SS}_{xy} = \\sum \\big(X_i - \\overline{X}\\big) \\big(Y_i - \\overline{Y}\\big)$$\n",
    "\n",
    "Тогава извадковият корелационен коефициент $r$ се определя като\n",
    "\n",
    "$$r = \\frac{\\text{SS}_{xy}}{\\sqrt{\\text{SS}_x} \\sqrt{\\text{SS}_y}}$$\n",
    "\n",
    "По ст-стите на $r$ може да се съди за наличие или отстъствие на корелация между две сл.в. Проверяме хипотезата за коефициент на корелация $\\rho$.\n",
    "\n",
    "$H_0: \\rho = 0$, т.е. $X$ и $Y$ са корелационно некорелирани срещу алтернативата\n",
    "\n",
    "$H_1: \\rho \\neq 0$, т.е. между $X$ и $Y$ има корелация при предварително избрано ниво на значимост $\\alpha$. За проверка на хипотезите използваме $t$-статистиката:\n",
    "\n",
    "$$t = \\frac{r}{\\sqrt{\\frac{1 - r^2}{n - 2}}}$$\n",
    "\n",
    "#### Коефициент на детерминация\n",
    "\n",
    "Коефициентът $\\beta_i$ показва степента на влияние на $X$ върху $Y$. Имаме:\n",
    "\n",
    "$$\\hat{\\beta}_i = \\frac{\\text{SS}_{xy}}{\\text{SS}_y}$$\n",
    "\n",
    "$$\\beta_0 = \\overline{y} - \\beta_1 \\overline{x}$$\n",
    "\n",
    "Частното\n",
    "\n",
    "$$r^2 = \\frac{\\big(\\text{SS}_{xy}\\big)^2}{\\sqrt{\\text{SS}_x}\\sqrt{\\text{SS}_y}}$$ се нарича коеф. на детерминация. Колкото по-близко до 1 е той, толкова по-близко до линейна е зависимостта и толкова набл. ст-сти на $Y$ са по-близки до ст-стите на $\\hat{Y}$, т.е. моделът добре обяснява данните.\n",
    "\n",
    "#### Стандартна грешка\n",
    "\n",
    "Стандартната грешка бележим с $s_e$ и измерва отклоненията на пресметнатите по модела ст-сти на зависимата променлива от реално наблюдаваните й ст-сти:\n",
    "\n",
    "$$s_e = \\sqrt{\\frac{\\sum(y_i - \\hat{y})^2}{n - 2}}$$\n",
    "\n",
    "При построяване на линеен регресионен модел се провяряват следните хипотези:\n",
    "\n",
    "$H_0: \\beta_0 = 0$ срещу $H_1: \\beta_0 \\neq 0$\n",
    "\n",
    "$H_0: \\beta_1 = 0$ срещу $H_1: \\beta_1 \\neq 0$\n",
    "\n",
    "т.е. дали коефициентите на модела са значими.\n",
    "\n",
    "### Оценка на модел\n",
    "\n",
    "Информация отностно адекватността на модела може да бъде получена от остатъците. Коефициентите на модела са оценени, така че сумата от квадратите да бъде минимизирана.\n",
    "\n",
    "Обикновено, анализът на остатъците се извършва с графични средства. Две общоприети проверки се реализират с графика на остатъците и предсказаните ст-сти.\n",
    "\n",
    "При адекватен модел остатъците са независими и имат нормално разпределение. Ако ст-стите са независими, графиката на остатъците и предсказаните ст-ти трябва да визуализира сл. разпръснати точки.\n",
    "\n",
    "За произволни ст-сти на предикторите $X$, за които е верен модела, сл.в. $\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1X$ е неизместена оценка на $EY$ и нейната дисперсия $DY$ може да се изчисли. Коефициентите на регресионните модели най-често се намират чрез метод на най-малките квадрати (МНМК).\n",
    "\n",
    "Подходите използвани за анализ на проста линейна регресия може да бъдат разширени за анализ на многофакторни (многомерни) модели, когато имаме повече от един фактор."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
