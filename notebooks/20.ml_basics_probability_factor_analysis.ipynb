{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "plt.xkcd()\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Факторен анализ\n",
    "\n",
    "Нуждата от факторен анализ е възникнала при обработка на данни от психо-социологични анкети. При такъв тип изследвания обикновено се предполага, че изследваното явление се описва с неизвестен (малък) брой фактори, които не можем да измерим директно. Единствено може да наблюдаваме голям брой променливи, които са функции от тях.\n",
    "\n",
    "## Цел на ФА?\n",
    "\n",
    "Построяване на модел, който обяснява вариация и коварция между множество наблюдения, като се представят чрез множество от фактори и тегла.\n",
    "\n",
    "## Представяне\n",
    "\n",
    "Търсим представяне на данните в следната форма:\n",
    "\n",
    "$$X = FL + E$$\n",
    "\n",
    "Където $X \\in R^{n \\times m}$ е матрицата на центрирараните и нормирани наблюдения, а $E \\in R^{n \\times m}$ на грешките\n",
    "\n",
    "#### Дефиниции\n",
    "\n",
    "- **Факторни тегла** се наричат коефициентите на разлагане на първоначалните променливи по факторите - $L \\in R^{k \\times m}$.\n",
    "- **Факторни стойности** се наричат оценените стойности на факторите за всяко наблюделние - $F \\in R^{n \\times k}$\n",
    "- **Общност** е относителната дисперсия на всяка променлива в новото й описание. Т.е. общностите показват доколко стойностите на конкретната променлива могат да бъдат предсказани или възстановени от факторните стойности.\n",
    "\n",
    "#### Основни задачи\n",
    "\n",
    "- Да се определи броят на необходимите фактори за описание на явлението\n",
    "- Да се намерят факторите\n",
    "\n",
    "### Главни компоненти\n",
    "\n",
    "Предложеният от Хотелинг метод на главните компоненти позволява да определим до колко даден брой фактори описват изучаваното явление. Допълнително, този метод намира и самите фактори.\n",
    "\n",
    "Главните компоненти съответстват на осите на елипсоида на разсейване на точките, представящи обектите (данните), в пространството на наблюдаваните променливи. Техният брой е равен на този на променливите. Главните компоненти могат да бъдат разглеждани като фактори, т.е. нови променливи, които са независими и описват извадката. Тази независимост позволява общата дисперсия да се представи като сбор на отделните (нови) променливи.\n",
    "\n",
    "Чрез отстраняване на факторите, които имат дисперсия по малка от предварително определена стойност $\\epsilon$, можем да редуцираме броя на променливите, като запазим задоволително описание на явлението.\n",
    "\n",
    "#### Метод на главните компоненти\n",
    "\n",
    "Този метод търси корелационна матрица $R$, където $r(x_i, x_j)$ е корелационният коефициент за променливите $x_i, x_j$. Сумата от собствените стойности на тази матрица е точно равна на броя на участващите променливи $p$. Теглото на даден фактор $F$ се определя от това до колко той обяснява общата вариация.\n",
    "\n",
    "Хотелинг е показал, че намирането на факторите, при фиксирано $k$ се дава от подпространството, образувано от първите $k$ собствени вектора.  Ако разгледаме разсейването на извадката $S^2 = \\sum{||x_i||^2}$, то ествествено е да търсим подпространство $H$ с размерност $k$, за фиксирано $k, 1 \\leq k \\leq m$, за което експерименталните точки биха се преместили минимално при своето проектиране $P$ върху него. При него най-малко би се изменила и дисперсията $S^2$:\n",
    "\n",
    "$$S^2 = \\sum{||x_i||^2 = \\sum{||P_kx_i||^2 + \\sum{||x_i - P_kx_i||^2}}}$$\n",
    "\n",
    "### Критерий за избор на $K$\n",
    "\n",
    "Изборът на $k$ се направлява от изискването да се представи възможно най-пълно да се представи най-пълно разсейването на извадката:\n",
    "\n",
    "$$\\sum_{i=1}^n||P_kx_i||^2 \\geq .95\\sum_{i=1}^n||x_i||^2$$\n",
    "\n",
    "#### Критерий на Кайзер\n",
    "\n",
    "Този критерий избира само собствените вектори със собствени стойности, които са по-големи от единица. Наистина, когато използваме корелационна матрица $\\sum{a_i} = trR = m$.\n",
    "\n",
    "## Кога да използваме ФА?\n",
    "\n",
    "- Получаване на взаимно независими факторни променливи, които може да бъдат използвани за регресионен анализ\n",
    "- Намаляване размерността на първоначалното пространство\n",
    "\n",
    "\n",
    "## Пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "- https://www.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/regression-library/v/introduction-to-residuals-and-least-squares-regression\n",
    "- https://onlinecourses.science.psu.edu/stat501/node/250\n",
    "- http://onlinestatbook.com/2/regression/intro.html\n",
    "- http://ci.columbia.edu/ci/premba_test/c0331/s7/s7_6.html\n",
    "- https://www.probabilitycourse.com/chapter8/8_5_0_linear_regression.php"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
